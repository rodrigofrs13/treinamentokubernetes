

# **Kubernetes**

# **Treinamentos**

Colocar ✔ quando concluído. 

## **Linux Foundation** 

- https://learning.edx.org/course/course-v1:LinuxFoundationX+LFS158x+3T2020/home✔




## **Curso de Introdução ao Kubernetes**

https://docs.google.com/presentation/d/1weqpBWa9FNjKc1ugCUIpwYYquvoIOFbUvEcZ9ZYapAg/edit#slide=id.g23786ddafa_0_68

- Apresentação https://www.youtube.com/watch?v=RuNTvYejG90&feature=youtu.be ✔ 
- 01 - Revisão docker - https://www.youtube.com/watch?v=bcRArpK00OU&feature=youtu.be ✔ 
- 02 - O que é Kubernetes?https://www.youtube.com/watch?v=X2r09kPi8aA&feature=youtu.be ✔ 
- 03 - Arquitetura do K8s - https://www.youtube.com/watch?v=bPFxwwSfSmk&feature=youtu.be ✔ 
- 04 Conceitos importantes do K8s - https://www.youtube.com/watch?v=Y0kHzwifFEA&feature=youtu.be ✔ 
- 05 Instalação dos componentes do K8s - https://www.youtube.com/watch?v=7H61VJV0YI8&feature=youtu.be ✔ 
- 06 Configuração do K8s (53:48) - https://www.youtube.com/watch?v=V1g0alYqI1w&feature=youtu.be ✔ 
- 07 ReplicaSet (7:14) - https://www.youtube.com/watch?v=qfiQyTqzUqU&feature=youtu.be ✔ 
- 08 Deployment (18:52) - https://www.youtube.com/watch?v=2JbQkTF6TzU&feature=youtu.be ✔ 
- 09 Service (27:30) - https://www.youtube.com/watch?v=zGqMvzbWAJc&feature=youtu.be ✔ 
- 10 Microservices (7:48) - https://www.youtube.com/watch?v=SS748X6xvdk&feature=youtu.be ✔ 



## **AcloudGuru**



- ### **Kubernetes Quick Start** ✔
  - https://lucid.app/lucidchart/fc864348-11e5-47fd-a64d-82ba93d32bb3/view?page=c9hx29xGf93-#

- ### **Kubernetes Essentials ✔**
  - https://lucid.app/lucidchart/6d5625be-9ef9-411d-8bea-888de55db5cf/view?page=I_Too4-SqdGV#
  - https://github.com/linuxacademy/robot-shop.

- ### **Introduction to Kubernetes ✔**


- ### **Kubernetes Deep Dive**✔
  - https://github.com/nigelpoulton
  - https://github.com/ACloudGuru-Resources
  - https://github.com/ACloudGuru-Resources/Course_Kubernetes_Deep_Dive_NP

  
  
  
  
- ### **Kubernetes Security**✔


  - https://github.com/linuxacademy/content-kubernetes-security

    - https://lucid.app/lucidchart/d034d4e7-4f8f-46c2-ad9d-276cde0e0c48/view

  

- **Certified Kubernetes Administrator (CKA)**
  - https://acloudguru-content-attachment-production.s3-accelerate.amazonaws.com/1607459695041-devops-wb002%20-%20Certified%20Kubernetes%20Administrator%20-%20All%20Sections%20Combined.pdf


- ### **Kubernetes Security (Advanced Concepts)**

- ### **Advanced Networking with Kubernetes on AWS**

- ### **Backing up and Restoring Kubernetes Data in etcd**

- ### **Helm Deep Dive V3**

- ### A Practical Guide to Amazon EKS

- ### Learn Kubernetes by Doing

- **Monitoring Kubernetes With Prometheus**

  - https://lucid.app/lucidchart/3da24eca-0c4d-4f03-b202-ba8f455783d2/view?page=0_0#

  - *LAB - Monitoring in Kubernetes with Prometheus and Grafana*

  - *LAB - Kubernetes Monitoring with Prometheus*

  - *LAB - Creating Alerting Rules*

    

- ### **AIOps Essentials (Autoscaling Kubernetes with Prometheus Metrics)**

  - https://interactive.linuxacademy.com/diagrams/AIOpsEssentials.html

- ### **Kubernetes the Hard Way**
  - https://acloudguru-content-attachment-production.s3-accelerate.amazonaws.com/1596643768051-kthw-arch_1532028083.png
  - https://acloudguru-content-attachment-production.s3-accelerate.amazonaws.com/1596643791307-kubernetes-the-hard-way-slides_1536875619.pdf
  - https://github.com/kelseyhightower/kubernetes-the-hard-way



## **Kubernetes 101**

https://www.youtube.com/watch?v=IcslsH7OoYo&list=RDCMUCR-DXc1voovS8nhAvccRZhg&index=2

## **Udemy**

https://www.udemy.com/course/kubernetes-hands-on-the-complete-guide/learn/lecture/27575504?start=0#overview

https://www.udemy.com/course/certified-kubernetes-security-specialist/learn/lecture/23184246?start=0#overview



## **AWS**



- **Amazon Elastic Kubernetes Service (EKS) Primer**✔

  

- ### **Containers on AWS: Ecosystem Integration✔**

  ### **Running Containers on Amazon Elastic Kubernetes Service (Amazon EKS)**✔

- ### **Containers na AWS✔**
  - https://pages.awscloud.com/LATAM_TRAINCERT_WEBINAR_immersion-day-containers-video-series_20200331_7010z000001LIBT_LPVideos-CostOptimizationVideoSeries.html

  

  

- **Leitura**
  - https://github.com/terraform-aws-modules/terraform-aws-eks
  - https://aws.github.io/aws-eks-best-practices/



- ### Amazon EKS on the AWS Cloud Quick Start Reference Deployment
  - https://aws-quickstart.github.io/quickstart-amazon-eks/
  - https://aws-quickstart.github.io/



- ### **Workshops AWS**

  - https://www.eksworkshop.com/

  

- ### **WINDOWS CONTAINERS ON AWS**

  - https://ms-containers.workshop.aws/en/

  

  

- ### **DISASTER RECOVERY ON AWS**

  - https://disaster-recovery.workshop.aws/en/

  

- ### **BLUE/GREEN AND CANARY DEPLOYMENT FOR EKS AND ECS**

  - https://cicd-pipeline-cdk-eks-bluegreen.workshop.aws/en/



- ### **MANAGE YOUR EKS CLUSTER IN FULL-STACK WITH CDK**

  - https://cdk-eks-devops.workshop.aws/en/



- ### **INTRODUCTION TO AMAZON EKS**

  - https://eks-for-aws-summit-online.workshop.aws/



- ### **AMAZON EKS TERRAFORM WORKSHOP**

  - https://tf-eks-workshop.workshop.aws/



- ### **WELCOME TO THE AMAZON EC2 SPOT INSTANCES WORKSHOPS WEBSITE**

  - https://ec2spotworkshops.com/



- ### **AWS MODERNIZATION WORKSHOP**

  - https://aqua.awsworkshop.io/



- ### **APPLICATION MODERNIZATION WITH AWS, SNYK AND DOCKER**

  - https://docker-snyk.awsworkshop.io/



- ### **AWS MODERNIZATION WORKSHOP WITH HARNESS**

  - https://harness.awsworkshop.io/



- ### **Introduction to GitOps on EKS with Weaveworks**

  - https://weaveworks-gitops.awsworkshop.io/



- ### **HELLO** 

  - https://observability.workshop.aws/en/



- ### **AWS MODERNIZATION WORKSHOP: DEVSECOPS WITH ATLASSIAN & SNYK**

  - https://snyk-atlassian.awsworkshop.io/



- ### **Workshop Links**

  - https://workshops.aws/
  - https://awsworkshop.io/



- ### **Agregação de Links**

  - ### https://github.com/brunokktro/auladobruno






## **LinuxTips**

- ### **Descomplicando o Kubernetes** 


https://github.com/badtuxx/DescomplicandoKubernetes

- ### **multi etcd**

- ### Canary Deploy


https://www.youtube.com/watch?v=CTvsdWZrAW0

https://github.com/badtuxx/k8s-canary-deploy-example

- ### **helm**

  

## **Jayendra Patil**

https://jayendrapatil.com/certified-kubernetes-administrator-cka-learning-path/



## **Laboratório K8S**

- **Play with K8s**

https://labs.play-with-k8s.com/

- **Katacoda**

https://www.katacoda.com/courses/kubernetes

- **Tutorials**

https://kubernetes.io/docs/tutorials/

# **Documentação oficial**

https://kubernetes.io/pt-br/docs/home/


![image](./imagens/125138813-ba243600-e0e5-11eb-9b86-531dc4c54311.png)



## **K8S Teoria**

![image-20210729203449523](./imagens/image-20210729203449523.png)



## **The Big Picture -  K8s**

![image-20210819205057531](./imagens/image-20210819205057531.png)

![image-20210719201310997](./imagens/image-20210719201310997.png)



## Control Plane

O plano de controle é uma coleção de múltiplos componentes responsáveis por gerenciar o cluster-se globalmente. Essencialmente, o controle
avião controla o cluster. Os componentes individuais do plano de controle podem ser executados em qualquer máquina do cluster, mas geralmente são
executado em máquinas controladoras dedicadas.

![image-20210819204235085](./imagens/image-20210819204235085.png)



## **Master Node**

Os componentes da camada de gerenciamento tomam decisões globais sobre o cluster (por exemplo, agendamento de *pods*), bem como detectam e respondem aos eventos do cluster (por exemplo, iniciando um novo *[pod](https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/)* quando o campo `replicas` de um *Deployment* não está atendido).

https://kubernetes.io/docs/concepts/overview/components/

![image-20210816194814828](./imagens/image-20210816194814828.png)

**Sempre no node MASTER**

### **ETCD**

https://kubernetes.io/pt-br/docs/concepts/overview/components/

Armazenamento de valor de chave consistente e altamente disponível usado como armazenamento de apoio do Kubernetes para todos os dados do cluster.

Etcd é o armazenamento de dados de backend para o Cluster do Kubernetes. Ele fornece armazenamento de alta disponibilidade para todos os dados relacionados ao estado do cluster.

![image-20210816195041749](./imagens/image-20210816195041749.png)

- No **[ETCD](https://kubernetes.io/docs/concepts/overview/components/#etcd)** são armazenados o estado do cluster, rede e outras informações persistentes.
- É Stateful. 
- Se seu cluster Kubernetes usa etcd como armazenamento de apoio, certifique-se de ter um plano de [backup](https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/#backing-up-an-etcd-cluster) para esses dado.

#### **Backup/Restore etcd**

https://acloudguru-content-attachment-production.s3-accelerate.amazonaws.com/1596581276472-devops-wb002%20-%20S03-L06%20Backing%20Up%20and%20Restoring%20Etcd%20Cluster%20Data.pdf

https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/#backing-up-an-etcd-cluster



#### **Comandos**

| Descrição          | Comando                         |
| ------------------ | ------------------------------- |
| Lista pods do etcd | kubectl get pods -n kube-system |
|                    |                                 |
|                    |                                 |





### **kube-api-server**

É a central de operações do cluster k8s. Todas as chamadas, internas ou externas são tratadas por ele. Ele é o único que conecta no ETCD.

Fornece a API Kubernetes, a interface primária para o plano de controle e o próprio cluster. Ao interagir com seu Kubernetes cluster, você geralmente fará isso usando o API Kubernetes.

https://kubernetes.io/docs/concepts/overview/components/#kube-apiserver



![image-20210816200040215](./imagens/image-20210816200040215.png)

O servidor de API é um componente da [Camada de gerenciamento](https://kubernetes.io/pt-br/docs/reference/glossary/?all=true#term-control-plane) do Kubernetes que expõe a API do Kubernetes. O servidor de API é o *front end* para a camada de gerenciamento do Kubernetes.

O kube-apiserver foi projetado para ser escalonado horizontalmente — ou seja, ele pode ser escalado com a implantação de mais instâncias. Você pode executar várias instâncias do kube-apiserver e balancear (balanceamento de carga, etc) o tráfego entre essas instâncias.

**2.3.2.1 - Comandos**

| Descrição                | Comando                         |
| ------------------------ | ------------------------------- |
| Lista pods do api-server | kubectl get pods -n kube-system |
|                          |                                 |
|                          |                                 |

### **kube-scheduler**

https://kubernetes.io/pt-br/docs/concepts/overview/components/

Usa um algoritmo para verificar em qual node o pod deverá ser hospedado. Ele verifica os recursos disponíveis do node para verificar qual o melhor node para receber aquele pod.

kube-scheduler lida com agendamento, o processo de seleção de um nó disponível no cluster no qual executar contêineres

![image-20210816195123993](./imagens/image-20210816195123993.png)

**Comandos**

| Descrição          | Comando                         |
| ------------------ | ------------------------------- |
| Lista pods do etcd | kubectl get pods -n kube-system |
|                    |                                 |
|                    |                                 |

### **kube-controller-manager**

https://kubernetes.io/pt-br/docs/concepts/overview/components/

É o controle principal que interage com o `kube-apiserver` para determinar o seu estado. Se o estado não bate, o manager irá contactar o controller necessário para checar seu estado desejado. Tem diversos controllers em uso como: os endpoints, namespace e replication.

kube-controller-manager executa uma coleção de vários utilitários de controlador em um único processo. Esses controladores realizam uma variedade de tarefas relacionadas à automação dentro do Cluster Kubernetes

![image-20210816195229262](./imagens/image-20210816195229262.png)

Componente da camada de gerenciamento que executa os processos de [controlador](https://kubernetes.io/docs/concepts/architecture/controller/).

Logicamente, cada *[controlador](https://kubernetes.io/docs/concepts/architecture/controller/)* está em um processo separado, mas para reduzir a complexidade, eles todos são compilados num único binário e executam em um processo único.

Alguns tipos desses controladores são:

- Controlador de nó: responsável por perceber e responder quando os nós caem.

- Controlador de *Job*: Observa os objetos *Job* que representam tarefas únicas e, em seguida, cria *pods* para executar essas tarefas até a conclusão.

- Controlador de *endpoints*: preenche o objeto *Endpoints* (ou seja, junta os Serviços e os *pods*).

- Controladores de conta de serviço e de *token*: crie contas padrão e *tokens* de acesso de API para novos *namespaces*.



**Comandos**

| Descrição          | Comando                         |
| ------------------ | ------------------------------- |
| Lista pods do etcd | kubectl get pods -n kube-system |
|                    |                                 |
|                    |                                 |

### **cloud-controller-manager**

Um componente da [camada de gerenciamento](https://kubernetes.io/pt-br/docs/reference/glossary/?all=true#term-control-plane) do Kubernetes que incorpora a lógica de controle específica da nuvem. O gerenciador de controle de nuvem permite que você vincule seu *cluster* na API do seu provedor de nuvem, e separar os componentes que interagem com essa plataforma de nuvem a partir de componentes que apenas interagem com seu cluster.

cloud-controller-manager fornece um interface entre o Kubernetes e vários plataformas em nuvem. Só é usado ao usar usando recursos baseados em nuvem o lado Kubernetes.



### **kubeadm**

https://kubernetes.io/docs/reference/setup-tools/kubeadm/

O kubeadm executa as ações necessárias para obter um cluster mínimo viável instalado e funcionando. Por design, ele se preocupa apenas com a inicialização, não com o provisionamento de máquinas. 

**Comandos**

| Descrição                                                    | Comando                                                |
| ------------------------------------------------------------ | ------------------------------------------------------ |
| kubeadm init --pod-network-cidr=10.24.4.0.0/16               | Inicia o cluster setanto o ip do pod-netowork -Flannel |
| kubeadm init --apiserver-advertise-address $(hostname -i)    |                                                        |
|                                                              |                                                        |
|                                                              |                                                        |
| kubeadm init --control-plane-endpoint "k8s-elb-01:6443" --upload-certs | Subir o cluster com elb                                |
| kubeadm token create --print-join-command                    | Restaurar o token do join p/ worker node               |
|                                                              |                                                        |
|                                                              |                                                        |
|                                                              |                                                        |



## **Worker Node**

https://kubernetes.io/pt-br/docs/concepts/overview/components/

https://kubernetes.io/docs/concepts/architecture/nodes/

![image-20210819204938530](./imagens/image-20210819204938530.png)

Os componentes de nó são executados em todos os nós, mantendo os *pods* em execução e fornecendo o ambiente de execução do Kubernetes.	

Nós do Kubernetes são as máquinas onde o contêineres gerenciados pela execução do cluster. Um cluster pode tem qualquer número de nós. Vários componentes de nó gerenciam contêineres no máquina e se comunicar com o plano de controle.

![image-20210816194858155](./imagens/image-20210816194858155.png)

### **kube-proxy**

O **kube-proxy** é o responsável por gerenciar a rede para os contêineres, é o responsável por expor portas dos mesmos.

kube-proxy é um proxy de rede. Ele é executado em cada nó e lida com algumas tarefas relacionadas ao fornecimento rede entre contêineres e serviços no
agrupar. 

https://kubernetes.io/docs/concepts/overview/components/#kube-proxy

Trata da comunicação entre os Nodes.

- **CBR0 - Cluster Bridge Zero**  
- **IPTABLES Mode** - Antigo
- **IPVS Mode** - Novo

![image-20210726215128527](./imagens/image-20210726215128527.png)

### **container runtime**

O agente de execução (*runtime*) de contêiner é o software responsável por executar os contêineres.

O tempo de execução do contêiner não está integrado ao Kubernetes. Isto é uma parte separada do software responsável por realmente executando contêineres na máquina. O Kubernetes oferece suporte a vários tempos de execução de contêineres implementações. Alguns tempos de execução de contêineres populares são Docker e containerd.

![image-20210816200447426](./imagens/image-20210816200447426.png)

### **kubelet**

https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/

O **[kubelet](https://kubernetes.io/docs/concepts/overview/components/#kubelet)** interage com o Docker instalado no node e garante que os contêineres que precisavam estar em execução realmente estão.

Kubelet é o agente Kubernetes executado em cada nó. Ele se comunica com o plano de controle e garante que os contêineres sejam executados em seu nó como instruído pelo plano de controle. Kubelet também lida com o processo de geração de relatórios status do contêiner e outros dados sobre contêineres de volta ao plano de controle.

![image-20210816200243381](./imagens/image-20210816200243381.png)

- node agent

- instalado em todos os nodes - master e worker
- Conversa com API Server

 

**Comandos**

| Descrição                   | Comando                                                  |
| --------------------------- | -------------------------------------------------------- |
| Lista Nodes                 | kubectl get nodes                                        |
| Describe Node               | kubectl describe node "*node_name*"                      |
| Pegar bloco de ip dos nodes | kubectl get nodes -o jsonpath='{.items[*].spec.podCIDR}' |
|                             |                                                          |

##############################################################################################

## **Demais componentes**



##############################################################################################

### **Namespaces**

https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/

Os namespaces fornecem um escopo para nomes. Os nomes dos recursos precisam ser exclusivos em um namespace, mas não entre os namespaces.

Específica com "**-n**", se não especificar nenhuma ele lista da namespace "*default*". 

**Comandos**

| Descrição                     | Comandos                                                     |
| ----------------------------- | ------------------------------------------------------------ |
| Lista namespaces              | kubectl get namespace / kubectl get ns                       |
| Cria namespaces               | kubectl create namespace "*nomedanamespace*"                 |
| Deleta namespaces             | kubectl delete namespaces <insert-some-namespace-name>       |
| Lista Pods com a namespace    | kubect get pods --namespace "*nomedanamespace*" / kubect get pods --n "*nomedanamespace*" |
| Lista Pods de todas namespace | kubect get pods --all-namespaces                             |
|                               |                                                              |
|                               |                                                              |
|                               |                                                              |
|                               |                                                              |



Create a new YAML file called `my-namespace.yaml` with the contents:

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: <insert-namespace-name-here>
```

Then run:

```
kubectl create -f ./my-namespace.yaml
```



**Setting the namespace for a request**

To set the namespace for a current request, use the `--namespace` flag.

For example:

```shell
kubectl run nginx --image=nginx --namespace=<insert-namespace-name-here>

```



No POD a namespace é declarada no metadata. 

![image-20210726205550668](./imagens/image-20210726205550668.png)



##############################################################################################

### **Network**

https://kubernetes.io/pt-br/docs/concepts/cluster-administration/networking/



![image-20210729212050005](./imagens/image-20210729212050005.png)



**Container Network Interface**

Para prover a rede para os contêineres, o k8s utiliza a especificação do **CNI**, Container Network Interface.

CNI é uma especificação que reúne algumas bibliotecas para o desenvolvimento de plugins para configuração e gerenciamento de redes para os contêineres. Ele provê uma interface comum entre as diversas soluções de rede para o k8s. Você encontra diversos plugins para AWS, GCP, Cloud Foundry entre outros.

Mais informações em: https://github.com/containernetworking/cni

Enquanto o CNI define a rede dos pods, ele não te ajuda na comunicação entre os pods de diferentes nodes.

As características básicas da rede do k8s são:

- Todos os pods conseguem se comunicar entre eles em diferentes nodes;
- Todos os nodes pode se comunicar com todos os pods;
- **Não utilizar NAT.**

**Todos os IPs dos pods e nodes são roteados sem a utilização de [NAT](https://en.wikipedia.org/wiki/Network_address_translation). **

Isso é solucionado com a utilização de algum software que te ajudará na criação de uma rede Overlay. Seguem alguns:

- [Weave](https://www.weave.works/docs/net/latest/kube-addon/)
- [Flannel](https://github.com/coreos/flannel/blob/master/Documentation/kubernetes.md)
- [Canal](https://github.com/tigera/canal/tree/master/k8s-install)
- [Calico](https://docs.projectcalico.org/latest/introduction/)
- [Romana](http://romana.io/)
- [Nuage](https://github.com/nuagenetworks/nuage-kubernetes/blob/v5.1.1-1/docs/kubernetes-1-installation.rst)
- [Contiv](http://contiv.github.io/)

**Mais utilizados Waeve ou Flannel. **

Mais informações em: https://kubernetes.io/docs/concepts/cluster-administration/addons/



**2.6.5.1 - Comandos**

| Descrição             | Comando                         |
| --------------------- | ------------------------------- |
| Lista pods do coredns | kubectl get pods -n kube-system |
|                       |                                 |
|                       |                                 |

##############################################################################################

### **DNS**

https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/

![image-20210726212636211](./imagens/image-20210726212636211.png)

 Kubelet define esse arquivo para cada pod.

```yaml
root@examplepod:/# cat /etc/resolv.conf
nameserver 10.96.0.10
search pod-example.svc.cluster.local svc.cluster.local cluster.local ec2.internal
options ndots:5

```



### 

##############################################################################################

**2.6.5 - Replicas e Replicas Set**

https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/

O objetivo de um **ReplicaSet** é manter um conjunto estável de pods de réplica em execução a qualquer momento. Como tal, costuma ser usado para garantir a disponibilidade de um número especificado de pods idênticos

**Anatomia de um replica set.** 

![image-20210726214240452](./imagens/image-20210726214240452.png)



Detalhamento do arquivo yaml

```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: frontend
  labels:
    app: nginx
    tier: frontend
spec:
  replicas: 2  											--->> Numero de replicas
  selector:
    matchLabels: 
      tier: frontend
    matchExpressions:
      - {key: tier, operator: In, values: [frontend]}
  template:
    metadata:
      labels:
        app: nginx
        tier: frontend
    spec:
      containers:
      - name: nginx
        image: darealmc/nginx-k8s:v1
        ports:
        - containerPort: 80
```

Para verificar se uma replica set controla o pod:

descbribe no pod

verifique a saida: Controlled By

![image-20210726213935171](./imagens/image-20210726213935171.png)

**2.3.5.1 - Comandos**



| Descrição               | Comando                                                      |
| ----------------------- | ------------------------------------------------------------ |
| Describe na replica set | kubectl describe rs/"*nomedareplica*"                        |
| Escala replicas         | kubectl scale rs/"*nomedareplica*"--replicas="*numero de replicas*" |
| Deleta replica set      | kubectl delete rs/"*nomedareplica*"                          |
|                         | kubectl get rs/"*nomedareplica*"                             |
|                         |                                                              |
|                         |                                                              |
|                         |                                                              |
|                         |                                                              |
|                         |                                                              |



##############################################################################################

### **Services**

https://kubernetes.io/docs/concepts/services-networking/service/

Uma maneira abstrata de expor um aplicativo em execução em um conjunto de [Pods](https://kubernetes.io/docs/concepts/workloads/pods/) como um serviço de rede.



![image-20210729211710504](./imagens/image-20210729211710504.png)

Com o Kubernetes, você não precisa modificar seu aplicativo para usar um mecanismo de descoberta de serviço desconhecido. O Kubernetes fornece aos pods seus próprios endereços IP e um único nome DNS para um conjunto de pods e pode fazer o balanceamento de carga entre eles. 

É uma forma de você expor a comunicação através de um **NodePort** ou **LoadBalancer** para distribuir as requisições entre diversos Pods daquele Deployment. Funciona como um balanceador de carga.

**Tipos de Services:**

- **NodePort:** Sempre acessível de **DENTRO** do Cluster - Por Porta
- **ClusterIP:** Sempre acessível de **FORA** do Cluster - Por IP
- **LoadBalancer:** Integração com Cloud Publica

![image-20210729213308068](./imagens/image-20210729213308068.png)

**O IP e o nome do Service nunca muda.** 



O vinculo entre o Service e o Pod é feito pelo label informado no Selector conforme abaixo:

![image-20210726215532711](./imagens/image-20210726215532711.png)

Ele cria um IP virtual para os pods, mas o endpoint continua sendo o ip dos pods. 

![image-20210726215644723](./imagens/image-20210726215644723.png)





**Anatomia do Service**

```yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    run: nginx
  name: nginx-clusterip
  namespace: default
spec:
  externalTrafficPolicy: Cluster
  ports:
  - port: 80
    protocol: TCP
    targetPort: 80
  selector:					----> determina quais pod´s farão parte do service
    run: nginx				----> determina quais pod´s farão parte do service
    sessionAffinity: None
  type: ClusterIP
```



**Comandos**

| Descrição         | Comandos                               |
| ----------------- | -------------------------------------- |
| Lista Services    | kubectl get services / kubectl get svc |
| Describe Services | kubectl describe svc "*service-name*"  |
|                   |                                        |
|                   |                                        |
|                   |                                        |
|                   |                                        |
|                   |                                        |
|                   |                                        |
|                   |                                        |

##############################################################################################

### **Deployment**

https://kubernetes.io/docs/concepts/workloads/controllers/deployment/



Você descreve um *estado desejado* em uma implantação, e a implantação [Controlador](https://kubernetes.io/docs/concepts/architecture/controller/) altera o estado real para o estado desejado em uma taxa controlada. Você pode definir implantações para criar novos **ReplicaSets** ou remover implantações existentes e adotar todos os seus recursos com novas implantações.

O deployment é uma ótima maneira de automatizar o gerenciamento de seus pods. O deployment permite que você especifique um estado desejado para um conjunto de pods. O cluster trabalhará constantemente para manter o estado desejado.

- **Scaling** - Entender mais
- **Rolling updates** - Entender mais
- **Self-Healing** - Entender mais

![image-20210802222430494](./imagens/image-20210802222430494.png)

![image-20210726220653723](./imagens/image-20210726220653723.png)



![image-20210726220716616](./imagens/image-20210726220716616.png)



![image-20210726220728016](./imagens/image-20210726220728016.png)



![image-20210726220739374](./imagens/image-20210726220739374.png)

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    run: prod-redis						--> Labels
  name: prod-redis
spec:
  selector:
    matchLabels:
      run: prod-redis
  replicas: 3							---> ReplicaSet
  minReadySeconds: 300					---> Tempo para chegar o pod como health
  strategy:								--> Estratégia de replicas
    rollingUpdate:
      maxSurge: 1						--> Vai criar uma nova réplica e deletar 1 / Pode ser qde ou %
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      labels:
        run: prod-redis						--> Labels
    spec:
      containers:
      - image: redis:4.0
        name: redis
```



Stateful Sets

StatefulSet é o objeto da API de carga de trabalho usado para gerenciar aplicações stateful. 

Como uma implantação, um StatefulSet gerencia pods com base em uma especificação de contêiner idêntica. 

Ao contrário de uma implantação, um StatefulSet mantém uma identidade persistente para cada um de seus pods. 

Esses pods são criados com a mesma especificação, mas não são intercambiáveis: cada um tem um identificador persistente, mantido em qualquer reagendamento.

Daemon Sets

Um DaemonSet garante que os nodes executem uma cópia de um pod. **À medida que os nodes são adicionados ao cluster, os pods são adicionados a eles.** 

Porém, sempre que os nodes forem removidos do cluster, esses pods são coletados como lixo. A exclusão de um DaemonSet limpará os pods criados.

Entre os diversos usos de um DaemonSet, podemos citar: 

- Daemon de armazenamento em cluster em cada node, como glusterd e ceph, por exemplo. 
- Daemon de coleta de logs em todos os nodes, como fluentd ou filebeat.
- Daemon de monitoramento de node em cada node, como Prometheus Node Exporter, Flowmill, Sysdig Agent, collectd, Dynatrace OneAgent, AppDynamics Agent, entre outros. 

Em um caso simples, um DaemonSet, cobrindo todos os nodes, seria usado para cada tipo de daemon. 

Uma configuração mais complexa pode usar vários DaemonSets para um único tipo de daemon. 

No entanto, com diferentes sinalizadores e/ou diferentes solicitações de memória e CPU para cada tipo de hardware.

**Anotações Importantes**

- **Um tipo Pod por deployment, mas pode ter varias replicar desse pod (replicas set)**
- **Sempre cria uma nova replica set quando vai fazer o rollout**
- **Sempre utilizar a flag "--record" no apply para criar o history do rollout**

**Comandos**

| Descrição                          | Comando                                                      |
| ---------------------------------- | ------------------------------------------------------------ |
| Altera imagem no deploy            | kubectl set image deployment.v1.apps/"*nome-deployment*" nginx="image" |
| Para acompanhar as atualizações    | kubectl describe deploy "*nome-deployment*"                  |
| Cria deployment básico             | kubectl create deployment "*nome-deployment*" --image=nginx  |
| Escala deployment                  | kubectl scale deployment "*nome-deployment*" --replicas="*qde-replicas*" |
| Opção DryRun não Cria o Deployment | kubectl create deployment meu-nginx --image=nginx **--dry-run=client** -o yaml > deployment-template.yaml |
| Acompanha o rollout da app         | kubectl rollout status deploy "*nome-do-deploy*"             |
| History dos rolouts                | kubectl.exe rollout history deploy test                      |
| Ver alterações na revisão          | kubectl.exe rollout history deploy test --revision=3         |
| Volta na versão tageada            | kubectl.exe rollout undo deploy test                         |
|                                    |                                                              |
|                                    |                                                              |



### 

##############################################################################################

### **Endpoints**

**Sempre pega com o Endpoint os pods que estão no Selector.**

O vinculo entre o Service e o Pod é feito pelo label informado no Selector conforme abaixo:

![image-20210726215532711](./imagens/image-20210726215532711.png)

![image-20210729212754923](./imagens/image-20210729212754923.png)

##############################################################################################

### **Storage**

Os volumes são um diretório que contém dados acessíveis aos contêineres em um pod. Um volume Kubernetes tem a mesma vida útil que o pod que o encapsula. 

Ele sobrevive a todos os contêineres executados no pod e os dados são preservados quando um contêiner é reiniciado.

O Kubernetes suporta muitos tipos de volumes e um pod pode usar todos eles simultaneamente.

https://kubernetes.io/docs/concepts/storage/

![image-20210802203359146](./imagens/image-20210802203359146.png)

**Volumes**

https://kubernetes.io/docs/concepts/storage/volumes/

**Container Storage Interface (CSI)**

https://kubernetes.io/blog/2019/01/15/container-storage-interface-ga/

![image-20210802204057322](C:\Users\brik\AppData\Roaming\Typora\typora-user-images\image-20210802204057322.png)



**Persistent Volumes**

https://kubernetes.io/docs/concepts/storage/persistent-volumes/

![image-20210802204251424](./imagens/image-20210802204251424.png)

**EmptyDir** 

Um volume do tipo **EmptyDir** é criado sempre que um Pod é atribuído a um nó existente. Esse volume é criado inicialmente vazio, e todos os contêineres do Pod podem ler e gravar arquivos no volume.

Esse volume não é um volume com persistência de dados. Sempre que o Pod é removido de um nó, os dados no `EmptyDir` são excluídos permanentemente. É importante ressaltar que os dados não são excluídos em casos de falhas nos contêineres.

Disco disponível somente enquando o pod estiver rodando.

Recomendado para logs por exemplo.

Disco no Node em /var/lib/kubelet/pods , find . -iname "*nomedodisco*"



**Persistent Volume**

O subsistema **PersistentVolume** fornece uma API para usuários e administradores que resume detalhes de como o armazenamento é fornecido e consumido pelos Pods. Para o melhor controle desse sistema foi introduzido dois recursos de API: `PersistentVolume` e `PersistentVolumeClaim`.

Um **PersistentVolume** (PV) é um recurso no cluster, assim como um nó. Mas nesse caso é um recurso de armazenamento. O PV é uma parte do armazenamento no cluster que foi provisionado por um administrador. Os PVs tem um ciclo de vida independente de qualquer pod associado a ele. Essa API permite armazenamentos do tipo: NFS, ISCSI ou armazenamento de um provedor de nuvem específico.

Um **PersistentVolumeClaim** (PVC) é semelhante a um Pod. Os Pods consomem recursos de um nó e os PVCs consomem recursos dos PVs.

Mas o que é um PVC? Nada mais é do que uma solicitação de armazenamento criada por um usuário.

Vamos criar um `PersistentVolume` do tipo `NFS`, para isso vamos instalar os pacotes necessários para criar um NFS Server no GNU/Linux.

Sequencia: Cria o **PV** depois o **PVC**.



**PV** é criado no WorkerNode.

**PVC** é o que aponta no POD.

**Reclaim Policy no PV**

- Retain
- Detele

![image-20210802204753235](./imagens/image-20210802204753235.png)

![image-20210802204956898](./imagens/image-20210802204956898.png)



**Storage Classes**

Um StorageClass fornece uma maneira para os administradores descreverem as "classes" de armazenamento que oferecem.

https://kubernetes.io/docs/concepts/storage/storage-classes/

![image-20210802205318959](./imagens/image-20210802205318959.png)





**Comandos**



| Descrição             | Comando                      |
| --------------------- | ---------------------------- |
| Listar o StorageClass | kubect get sc                |
|                       | kubectl describe sc "nomesc" |
|                       |                              |
|                       |                              |
|                       |                              |

##############################################################################################



### **Scaling**

#### **Horizontal Pod Autoscaler - HPA**

https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/

O autoescalador horizontal de pods dimensiona automaticamente o número de pods em um controlador de replicação, implantação, conjunto de réplicas ou conjunto com estado com base na utilização de CPU observada (ou, com suporte a [métricas personalizadas](https://git.k8s.io/community/contributors/design-proposals/instrumentation/custom-metrics-api.md) , em algumas outras métricas fornecidas pelo aplicativo).

![image-20210803193803808](./imagens/image-20210803193803808.png)

![image-20210803194211601](./imagens/image-20210803194211601.png)

**ENTENDER MAIS SOBRE O CALCULO DE CPU**



#### **Vertical Pod Autoscaler - VPA**

Em Alpha 

#### **Cluster Autoscaler - CA**

**Para Nodes**



#### **Anotações Importantes**

- **Um HPA por Deployment**
- **autoscaling/v2 tem custom metrics/cpu/memory**
- **No Cluster Autoscaler sempre utilizar Pod Resource Requests**
- **No Cluster Autoscaler  não mexa com os pools de nós**
- **No Cluster Autoscaler  verifique sua nuvem para suporte** (--enable-autoscaling)
- **No Cluster Autoscaler teste o desempenho em grandes clusters**

#### **Comandos**

| Descrição            | Comando         |
| -------------------- | --------------- |
| Listas todos os hpas | kubectl get hpa |
|                      |                 |
|                      |                 |
|                      |                 |
|                      |                 |

##############################################################################################

### **Labels**

https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/

Labels permitem que os usuários mapeiem suas próprias estruturas organizacionais em objetos do sistema de maneira fracamente acoplada, sem exigir que os clientes armazenem esses mapeamentos.

Uso para filtros 

É um par chave-valor

Pode-se usar até 3.

## 

O **Node Selector** é uma forma de classificar nossos nodes como por exemplo nosso node `elliot-02` que possui disco **SSD** e está localizado no DataCenter `UK`, e o node `elliot-03` que possui disco **HDD** e está localizado no DataCenter `Netherlands`.

Para criar pods em nodes com o Label "disk""HDD", adiciona no deployment  no spec do pod a opção abaixo.

```yaml
 nodeSelector:
              disk: HDD
```



**Labels recomentados**

https://kubernetes.io/docs/concepts/overview/working-with-objects/common-labels/

#### **Comandos**



| Descrição                               | Comando                                                      |
| --------------------------------------- | ------------------------------------------------------------ |
| Listas todos os pods com Label          | kubectl get pods --show-labels                               |
| Listar os pods com o Label especificado | kubectl get pods -l dc="label"                               |
| Lista os pods com o label "DC"          | kubectl get pods -L "label"                                  |
| Setar Label no pod                      | kubectl label pod "nomedopod" "label"="valor" -n "namespace" |
| Deletar pod com Label especifico        | kubectl delete pod -l "label"="valor" -n "namespace"         |
|                                         |                                                              |
|                                         |                                                              |
|                                         |                                                              |
|                                         |                                                              |



##############################################################################################

### **[Supervisord](http://supervisord.org/)** 

é o responsável por monitorar e restabelecer, se necessário, o `kubelet` e o Docker. Por esse motivo, quando existe algum problema em relação ao kubelet, como por exemplo o uso do driver `cgroup` diferente do que está rodando no Docker, você perceberá que ele ficará tentando subir o kubelet frequentemente.

##############################################################################################

### **Kubectl Taint**

O **Taint** nada mais é do que adicionar propriedades ao nó do cluster para impedir que os pods sejam alocados em nós inapropriados.

Por exemplo, todo nó `master` do cluster é marcado para não receber pods que não sejam de gerenciamento do cluster.

O nó `master` está marcado com o taint `NoSchedule`, assim o scheduler do Kubernetes não aloca pods no nó master, e procurar outros nós no cluster sem essa marca.

```yaml
## NoSchedule - Novos containers não são executados no node
**Habilitado** - kubectl taint node k8s-worker-01 key1=value1:NoSchedule
**Desabilitado** - kubectl taint node k8s-worker-01 key1=value1:NoSchedule-

## NoExecute - Não executa containers no node, ele mata e migra para outro node
**Habilitado** - kubectl taint node elliot-03 key1=value1:NoExecute
**Desabilitado** - kubectl taint node elliot-03 key1=value1:NoExecute-
```

##############################################################################################

### **Context**

##############################################################################################

### **Alias**

alias kk=kubectl



##############################################################################################

# **Setup WEB UI**

https://acloudguru-content-attachment-production.s3-accelerate.amazonaws.com/1596555315055-302-kubernetessecuritydashboardsetup_1558387085.pdf

kubectl.exe apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta4/aio/deploy/recommended.yaml

https://docs.aws.amazon.com/pt_br/eks/latest/userguide/dashboard-tutorial.html

**Get Token**

kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk '{print $1}')



**Acesso**

http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/#!/login

##############################################################################################



# **POD´s**

https://kubernetes.io/docs/concepts/workloads/pods/

https://kubernetes.io/docs/reference/kubectl/cheatsheet/#interacting-with-running-pods

**[Pod](https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/)** é a menor unidade que você irá tratar no k8s. 

- **Você poderá ter mais de um contêiner por Pod**, porém vale lembrar que eles dividirão os mesmos recursos, como por exemplo IP. 
- Uma das boas razões para se ter mais de um contêiner em um Pod é o fato de você ter os logs consolidados.
- O Pod, por poder possuir diversos contêineres, muitas das vezes se assemelha a uma VM, onde você poderia ter diversos serviços rodando compartilhando o mesmo IP e demais recursos.
- Os Pods podem se comunicar sem **NAT**.





![image-20210726205830178](./imagens/image-20210726205830178.png)

##############################################################################################

## **Anatomia de um Pod ** 

```yaml
apiVersion: v1									-----> Versão da API
kind: Pod									    ----> O que quer criar 
metadata:
  name: examplepod								----> nome do pod
  namespace: pod-example						----> nome da namespace
spec:											---->  espeficicações do container
  volumes:										---->  volumes
  - name: html
    emptyDir: {}
  containers:
  - name: webcontainer							---->  nome do container
    image: nginx								---->  imagem do container
    volumeMounts:
    - name: html
      mountPath: /usr/share/nginx/html
  - name: filecontainer
    image: debian
    volumeMounts:
    - name: html
      mountPath: /html
    command: ["/bin/sh", "-c"]
    args:
      - while true; do
         date >> /html/index.html;
         sleep 1;
        done
```



##############################################################################################

## **LifeCycle**

https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/

### **Probes**

https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes

https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/

Uma [Probe](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#probe-v1-core) é um diagnóstico realizado periodicamente pelo [kubelet](https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/) em um Container. Para realizar um diagnóstico, o kubelet chama um [Handler](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#handler-v1-core) implementado pelo contêiner. 

- [ExecAction](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#execaction-v1-core) : [executa](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#execaction-v1-core) um comando especificado dentro do contêiner. O diagnóstico é considerado bem-sucedido se o comando sair com um código de status 0.
- [TCPSocketAction](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#tcpsocketaction-v1-core) : executa uma verificação de TCP no endereço IP do pod em uma porta especificada. O diagnóstico é considerado bem-sucedido se a porta estiver aberta.
- [HTTPGetAction](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.22/#httpgetaction-v1-core) : executa uma `GET`solicitação HTTP no endereço IP do pod em uma porta e caminho especificados. O diagnóstico é considerado bem-sucedido se a resposta tiver um código de status maior ou igual a 200 e menor que 400.

Cada Probe tem um de três resultados:

- `Success`: O contêiner passou no diagnóstico.
- `Failure`: O contêiner falhou no diagnóstico.
- `Unknown`: O diagnóstico falhou, portanto, nenhuma ação deve ser tomada.

O kubelet pode, opcionalmente, executar e reagir a três tipos de Probes em contêineres em execução:

- ####  **LivenessProbe**

  Indica se o contêiner está em execução. Se a investigação de liveness falhar, o kubelet elimina o contêiner e o contêiner fica sujeito à sua [política de reinicialização](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy) . Se um contêiner não fornecer um teste de atividade, o estado padrão é `Success`.

  

Exemplo

```yaml
apiVersion: v1
kind: Pod
metadata:
  labels:
    test: liveness
  name: liveness-exec
spec:
  containers:
  - name: liveness
    image: k8s.gcr.io/busybox
    args:
    - /bin/sh
    - -c
    - touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600
    livenessProbe:
      exec:
        command:
        - cat
        - /tmp/healthy
      initialDelaySeconds: 5  #--->> Expecifica que o kubelet deve aguardar 5 segundos antes de realizar a primeira checagem
      periodSeconds: 5    #---->> Especifica que o kubelet deve realizar uma sondagem de atividade a cada 5 segundos.
```



- **readinessProbe**

  Indica se o contêiner está pronto para responder às solicitações. Se a investigação de prontidão falhar, o controlador de endpoints remove o endereço IP do pod dos endpoints de todos os serviços que correspondem ao pod. O estado padrão de prontidão antes do atraso inicial é `Failure`. Se um contêiner não fornecer uma investigação de prontidão, o estado padrão será `Success`.

  São usadas para permitir que o kubelet saiba quando o aplicativo está pronto para aceitar novo tráfego. Se o aplicativo precisar de algum tempo para inicializar o estado após o início do processo, configure a sondagem de prontidão para dizer ao Kubernetes para esperar antes de enviar novo tráfego.

  Exemplo

  ```yaml
  apiVersion: v1
  kind: Pod
  metadata:
    name: readiness-pod
  spec:
    containers:
    - name: nginx
      image: nginx:1.19.1
  	readinessProbe:
  	  httpGet:
  		path: /
  	    port: 80
  	initialDelaySeconds: 5 #--->> Expecifica que o kubelet deve aguardar 5 segundos antes de realizar a primeira checagem
  	periodSeconds: 5 #---->> Especifica que o kubelet deve realizar uma sondagem de atividade a cada 5 segundos.
  ```

  

- **startupProbe**

  Indica se o aplicativo dentro do contêiner foi iniciado. Todos os outros probes são desabilitados se um teste de inicialização for fornecido, até que seja bem-sucedido. Se a investigação de inicialização falhar, o kubelet elimina o contêiner e o contêiner fica sujeito à sua [política de reinicialização](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy) . Se um contêiner não fornece uma investigação de inicialização, o estado padrão é `Success`.

  Exemplo

  ```yaml
  apiVersion: v1
  kind: Pod
  metadata:
    name: startup-pod
  spec:
    containers:
    - name: nginx
      image: nginx:1.19.1
      startupProbe:   #--->> startupProbe       
        httpGet:
          path: /
  	    port: 80
  	 failureThreshold: 30 #--> número de tentativas antes de marcar a detecção como falha. Para liveness probes, isso levará ao reinício do pod. Para readiness probes, isso marcará o pod como não preparado.
  	 periodSeconds: 10
  ```

  

### **Restart Policies**

https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy

https://acloudguru-content-attachment-production.s3-accelerate.amazonaws.com/1597437528004-devops-wb002%20-%20S05-L05%20Building%20Self-Healing%20Pods%20with%20Restart%20Policies.pdf

K8s pode reiniciar contêineres automaticamente quando eles falham. As políticas de reinicialização permitem que você personalizar este comportamento definindo quando você quer que os contêineres de um pod sejam reiniciado automaticamente.
As políticas de reinicialização são um componente importante de aplicativos de autocura, que são reparado automaticamente quando um problema 
surge. 
Existem três valores possíveis para um pod política de reinicialização em K8s: Always, OnFailure e Never. **O valor padrão é Always.** 

-  **Always**

  É a política de reinicialização padrão no K8s. Com esta política, os contêineres sempre serão reiniciado se eles pararem, mesmo se tiverem concluído
  com sucesso. Use esta política para aplicativos que deve estar sempre em execução.

- **OnFailure**

  A política de reinicialização OnFailure irá reiniciar contêineres apenas se o processo de contêiner sair com um código de erro ou o contêiner é
  determinado a não ser saudável por uma vida sonda. Use esta política para aplicativos que precisa ser executado com sucesso e, em seguida, parar.

- **Never**

  A política de Never fará com que o pod contêineres para nunca serem reiniciados, mesmo se o o contêiner sai ou uma investigação de atividade falha. Usar isso para aplicativos que devem ser executados uma vez e nunca será reiniciado automaticamente.

Exemplo:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: always-pod
spec:
  restartPolicy: Always #--->> Inserir qual Restart Police utilizar - Always ou OnFailure ou Never
  containers:
  - name: busybox
    image: busybox
    command: ['sh', '-c', 'sleep 10']
```

##############################################################################################

## **Resource CPU/Memory**

https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#resource-requests-and-limits-of-pod-and-container

https://acloudguru-content-attachment-production.s3-accelerate.amazonaws.com/1597437414250-devops-wb002%20-%20S05-L03%20Managing%20Container%20Resources.pdf



##############################################################################################

### **Resource Request**

Exemplo

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: big-request-pod
spec:
  containers:
  - name: busybox
    image: busybox
    command: ['sh', '-c', 'while true; do sleep 3600; done']
    resources:
      requests:
	    cpu: "10000m"
	    memory: "128Mi"

```



### **Resource Limits**

Pod é encerrado por conta do limite de memória excedido. E caso continuarmos a acompanhar, veremos que o Pod será sempre restartado.

Exemplo

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: big-request-pod
spec:
  containers:
  - name: busybox
    image: busybox
    command: ['sh', '-c', 'while true; do sleep 3600; done']
    resources:
      limits:
	    cpu: "250m"
	    memory: "128Mi"
```

Exemplo com Limits e Request

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: resource-pod
spec:
  containers:
  - name: busybox
    image: busybox
    command: ['sh', '-c', 'while true; do sleep 3600; done']
    resources:
      requests:
        cpu: "250m"
        memory: "128Mi"
      limits:
        cpu: "500m"
        memory: "256Mi"

```





**Atenção! 1 core de CPU corresponde a 1000m (1000 milicore). Ao especificar 200m, estamos querendo reservar 20% de 1 core da CPU. Se fosse informado o valor 0.2 teria o mesmo efeito, ou seja, seria reservado 20% de 1 core da CPU.**







##############################################################################################

## **Secrets**

https://kubernetes.io/docs/concepts/configuration/secret/

Os Secreets são semelhantes aos ConfigMaps, mas são projetado para armazenar dados confidenciais, como senhas ou chaves de API, com mais segurança. Eles são criado e usado de forma semelhante ao ConfigMaps.

Exemplo Secrets

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-secret
type: Opaque
data:
secretkey1: <base64 String 1>
secretkey2: <base64 String 2>
```



Vincular o Secret no Pod

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: env-pod
spec:
  containers:
    - name: busybox
    image: busybox
    command: ['sh', '-c', 'echo "configmap: $CONFIGMAPVAR secret: $SECRETVAR"']
    env:
    - name: CONFIGMAPVAR
      valueFrom:
        configMapKeyRef:
          name: my-configmap
          key: key1
    - name: SECRETVAR   ------------>> Vinculando o Secet no POD
      valueFrom:
        secretKeyRef:
          name: my-secret
          key: secretkey1

```



##############################################################################################

## **ConfigMaps**

https://kubernetes.io/docs/concepts/configuration/configmap/

Você pode armazenar dados de configuração em Kubernetes usando ConfigMaps. Os ConfigMaps armazenam dados na forma de um mapa de valor-chave. Os dados do ConfigMap podem ser passado para o seu contêiner formulários.

Exemplo ConfigMap

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-configmap
data:
  key1: Hello, world!
  key2: |
    Test
    multiple lines
    more lines
```

Vinculando o ConfigMap no POD

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: env-pod
spec:
  containers:
    - name: busybox
    image: busybox
    command: ['sh', '-c', 'echo "configmap: $CONFIGMAPVAR secret: $SECRETVAR"']
    env:
    - name: CONFIGMAPVAR   ----------->> Vinculando o ConfigMap no POD
      valueFrom:
        configMapKeyRef:
          name: my-configmap
          key: key1
    - name: SECRETVAR
      valueFrom:
        secretKeyRef:
          name: my-secret
          key: secretkey1

```

##############################################################################################



**Comandos**

| Descrição                                                    | Comando                                         |
| :----------------------------------------------------------- | ----------------------------------------------- |
| Editar pod                                                   | kubect edit pod "*nomedopod*"                   |
| Lista todos os pods de todos as namespaces                   | kubectl get pods --all-namespaces               |
| Lista todos os pods de todos as namespaces  dentro dos worker nodes | kubectl get pods --all-namespaces -o wide       |
| Deleta Pod                                                   | kubectl delete pod "*nomepod*" -n "*namespace*" |
| Create Pod                                                   | kubectl create -f pod-exmeple.yaml              |
|                                                              |                                                 |
|                                                              |                                                 |
|                                                              |                                                 |
|                                                              |                                                 |





##############################################################################################

# **Management Tools**

## **kubectl**

kubectl é uma ferramenta de linha de comando que permite para interagir com o Kubernetes. kubectl usa a API Kubernetes para se comunicar com o cluster e realizar o seu comandos. 

https://kubernetes.io/docs/reference/kubectl/overview/

https://kubernetes.io/docs/concepts/overview/working-with-objects/object-management/

https://acloudguru-content-attachment-production.s3-accelerate.amazonaws.com/1604606241364-devops-wb002%20-%20S04-L02%20Kubectl%20Tips.pdf

https://acloudguru-content-attachment-production.s3-accelerate.amazonaws.com/1596636121024-devops-wb002%20-%20S04-L01%20Working%20with%20Kubectl.pdf



A figura a seguir mostra a estrutura dos principais comandos do `kubectl`.

![image-20210727204047129](./imagens/image-20210727204047129.png)



- kubectl get
- kubectl describe
- kubectl create
- kubectl apply
- kubectl delete
- kubectl exec



### **Comandos**

https://kubernetes.io/docs/reference/kubectl/cheatsheet/

| Comando                                                      | Descrição                                                    |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| kubectl get events                                           | Lista os eventos                                             |
| kubectl get componentstatus                                  | Status dos componentes                                       |
| kubectl api-resources                                        | Para listar os shots names                                   |
| kubectl get pods -o yaml                                     | Lista os pods no formato yaml                                |
| kubectl get pods -o json                                     | Lista os pods no formato json                                |
| kubectl get pods -n "*namespace*"                            | Lista os pods de uma determinada namespace                   |
| kubectl get pods --all-namespaces                            | Lista os pods de todas as namespace                          |
| kubectl get pods -n "*namespace*" --selector "*labels*"      | Selector é um filtro para Labels                             |
| kubectl describe pod "*pod-name*"                            | Describe nos pods                                            |
| kubectl run nginx --image=nginx                              | Cria um POD c/ a imagem nginx                                |
| kubectl get pods nginx **-o yaml**                           | Mostra o manifesto dos pods no formato yaml                  |
| kubectl run "*pod-name*" --image nginx **--dry-run=client**  | Opção DryRun não Cria o POD                                  |
| kubectl run "*pod-name*"  --image nginx **--dry-run=client** **-o yaml** | Opção DryRun não Cria o POD, mostra manifesto em yaml        |
| kubectl run "*pod-name*"  --image nginx **--dry-run=client** **-o yaml** > pod-template.yaml | Joga a saída do comando p/ arquivo pod-template.yaml         |
| kubectl get pods "*pod-name*"  -o yaml > meupod.yaml         | Cria um arquivo yaml com as infos do pod                     |
| kubectl get pods "*pod-name*"  -o yaml --export > meupod.yaml | Cria um arquivo yaml com as infos do pod, mas sem infos especificas |
| kubectl edit deploy "*nome-do-deploy*"                       | Edita on-line o deploy                                       |
| kubectl cluster-info                                         | Informações do cluster                                       |
| kubectl cluster-info dump                                    | Gerar Dump das infos do cluster                              |
| kubectl explain "*recurso*"                                  | Explica o recurso "main page"                                |
| kubectl expose                                               | Cria Services                                                |
| kubectl create deployment "*deploy-name*" --image=nginx --dry-run -o yaml > deployment.yml | Joga a saída do comando p/ arquivo deployment.yaml           |
|                                                              |                                                              |
|                                                              |                                                              |
|                                                              |                                                              |
|                                                              |                                                              |
|                                                              |                                                              |
|                                                              |                                                              |
|                                                              |                                                              |





## **kubeadm**

### **Comandos**

| Comando            | Descrição    |
| ------------------ | ------------ |
| kubeadm token list | Lista Tokens |
|                    |              |
|                    |              |
|                    |              |

## **Minikube**

Minikube permite que você defina automaticamente até um cluster Kubernetes de nó único local. É ótimo para ativar o Kubernetes e correndo rapidamente para o desenvolvimento finalidades.

## **Helm**

Helm fornece modelos e pacote gerenciamento de objetos Kubernetes. Vocês pode usá-lo para gerenciar seus próprios modelos (conhecido como gráficos).  Você também pode baixar e usar modelos compartilhados

Usa Charts.

## **Kompose**

Kompose ajuda a traduzir Docker compor arquivos em objetos Kubernetes. Se você está usando o Docker Compose para alguns parte de seu fluxo de trabalho,  você pode mover seu aplicativo para o Kubernetes facilmente com Kompose.

## **Kustomize**

Kustomize é uma configuração ferramenta de gestão para gestão Configurações de objeto do Kubernetes. Isto permite que você compartilhe e reutilize modelos
configurações para Kubernetes formulários.

Similar ao Helm.

##############################################################################################

# **Kubernetes Metrics Server**

Para visualizar métricas sobre os recursos pods e contêineres estão usando, precisamos de um add-on para coletar e fornecer esses dados. 

Esse complemento é o Kubernetes Metrics Server.

### Instalar o ADD-ON 

```shell
kubectl apply -f https://raw.githubusercontent.com/linuxacademy/content-cka-resources/master/metrics-server-components.yaml
```



### Métricas

```shell
kubectl get --raw /apis/metrics.k8s.io/
```



### **Comandos**

| Comando                                     | Descrição                        |
| ------------------------------------------- | -------------------------------- |
| kubectl top pod                             | Mostra consumo cpu/ram dos pods  |
| kubectl top pod --sort-by cpu               | Lista por consumo de CPU         |
| kubectl top pod --selector app=metrics-test | Lista pods com selector          |
| kubectl top node                            | Mostra consumo cpu/ram dos Nodes |
|                                             |                                  |



##############################################################################################

# **Service Account**

Uma Service Account é uma conta usada por processos de contêineres dentro de pods para autenticar com a API K8s.
Se seus pods precisam se comunicar com o API K8s, você pode usar Service Account  para controlar o acesso deles.

https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/

https://kubernetes.io/docs/reference/access-authn-authz/rbac/

https://acloudguru-content-attachment-production.s3-accelerate.amazonaws.com/1604087569423-devops-wb002%20-%20S04-L04%20Creating%20ServiceAccounts.pdf



Exemplo de criação de uma Service Account

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-serviceaccount
```

Exemplo de RoleBinding para Service Account

```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: sa-pod-reader
  namespace: default
subjects:
- kind: ServiceAccount
  name: my-serviceaccount
  namespace: default
roleRef:
  kind: Role
  name: pod-reader
  apiGroup: rbac.authorization.k8s.io

```



### **Comandos**



| Comando                                  | Descrição                |
| ---------------------------------------- | ------------------------ |
| kubectl create sa "nomedaserviceaccoint" | Criar Service Account    |
| kubectl get sa                           | Lista as Service Account |
| kubectl describe sa my-serviceaccount    |                          |
|                                          |                          |

##############################################################################################

# **Upgrade with kubeadm**

https://acloudguru-content-attachment-production.s3-accelerate.amazonaws.com/1623333677445-devops-wb002%20-%20S03-L05%20Upgrading%20K8s%20with%20kubeadm.pdf

https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/

## **Master Node**

1. Remover o Master Node do Cluster

   ```shell
   kubectl drain "master-node" --ignore-daemonsets
   ```

   

2. Upgrade kubeadm

   ```shell
   sudo apt-get update && \ sudo apt-get install -y --allow-change-held-packages kubeadm=1.21.1-00
   ```

   

3. Confirma a versão do kubeadm

   ```shell
   kubeadm version
   ```

   

4. Planejar os componentes que serão atualizados

   ```shell
   kubeadm upgrade plan v1.21.1
   ```

   

5. Efetuar o upgrade

   ```shell
   kubeadm upgrade apply v1.21.1
   ```

   

6. Atualizar kubelet e kubectl 

   ```shell
   *sudo apt-get update && \ sudo apt-get install -y --allow-change-held-packages kubelet=1.21.1-00 kubectl=1.21.1-00
   ```

   

7. Restart kubelet

   ```shell
   sudo systemctl daemon-reload && sudo systemctl restart kubelet
   ```

   

8. Valida de a versão foi atualizada no Master Node 

   ```shell
   kubectl get nodes
   ```

   

9. Volta o Master Node no Cluster 

   

   ```shell
   kubectl uncordon "master-node"
   ```

   

## **Worker Node**

1. Remover o Worker Node do Cluster

   ```shell
   kubectl drain "worker-node" --ignore-daemonsets*
   ```

   

2. Upgrade kubeadm

   ```shell
   sudo apt-get update && \ sudo apt-get install -y --allow-change-held-packages kubeadm=1.21.1-00*
   ```

   

3. Confirma a versão do kubeadm

   

   ```shell
   kubeadm version
   ```

   

4. Planejar os componentes que serão atualizados

   ```shell
   kubeadm upgrade node
   ```

   

5. Atualizar kubelet e kubectl 

   ```shell
   sudo apt-get update && \ sudo apt-get install -y --allow-change-held-packages kubelet=1.21.1-00 kubectl=1.21.1-00
   ```

   

6. Restart kubelet

   ```shell
   sudo systemctl daemon-reload && sudo systemctl restart kubelet
   ```

   

7. Valida de a versão foi atualizada no Master Node 

   ```shell
   kubectl get nodes
   ```

   

   Volta o Master Node no Cluster 

   ```shell
   kubectl uncordon "master-node"
   ```

   







##############################################################################################

# **Draining Node**

https://kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/

https://acloudguru-content-attachment-production.s3-accelerate.amazonaws.com/1596581256097-devops-wb002%20-%20S03-L04%20Safely%20Draining%20a%20K8s%20Node.pdf



## Ignoring DaemonSets

- **SchedulingDisabled** - Status do node onde o Kubernetes não irá mais colocar pods neste Worker Node.
- Pod criado sem deployment não é recriado. 

## **Uncordoning a Node**

- Após habilitar o nó com o "*uncordon*" o Kubernetes não rebalanceia os pods entre os outros Worker Node e o Worker Nodeinserido. 

## **Comandos**

| Descrição                               | Comando                                       |
| --------------------------------------- | --------------------------------------------- |
| Remove Worker Node                      | kubectl drain <node name>                     |
| Remove Worker Nodeignorando Daemon Sets | kubectl drain <node name> --ignore-daemonsets |
| Inclui o Worker Node no cluster         | kubectl uncordon <node name>                  |
|                                         |                                               |



##############################################################################################

# **High Availability**

## **Control Plane**

https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/

Ao usar vários Control Planes para alta disponibilidade, você provavelmente precisa se comunicar com o API Kubernetes por meio de um balanceador de carga. Isso inclui clientes como instâncias kubelet em execução nos Worker Nodes.

TODO - Ver o do linuxtips

![image-20210823194619251](./imagens/image-20210823194619251.png)





## **Stacked etcd**

https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/

Um cluster HA empilhado é uma [topologia em](https://en.wikipedia.org/wiki/Network_topology) que o cluster de armazenamento de dados distribuído fornecido pelo etcd é empilhado no topo do cluster formado pelos nós gerenciados pelo kubeadm que executam os componentes do Control Plane.

![image-20210823195011894](./imagens/image-20210823195011894.png)



## **External etcd**

https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/

Um cluster HA com etcd externo é uma [topologia em](https://en.wikipedia.org/wiki/Network_topology) que o cluster de armazenamento de dados distribuído fornecido pelo etcd é externo ao cluster formado pelos nós que executam os componentes do Control Plane.

![image-20210823195036875](./imagens/image-20210823195036875.png)

##############################################################################################

# **Security**

https://kubernetes.io/docs/tasks/administer-cluster/securing-a-cluster/

https://cheatsheetseries.owasp.org/cheatsheets/Kubernetes_Security_Cheat_Sheet.html

![image-20210816194455011](./imagens/image-20210816194455011.png)

## **Network Policies**

https://kubernetes.io/docs/concepts/services-networking/network-policies/#:~:text=By%20default%2C%20pods%20are%20non,not%20allowed%20by%20any%20NetworkPolicy.



![image-20210819201957114](./imagens/image-20210819201957114.png)



![image-20210819202011642](./imagens/image-20210819202011642.png)



![image-20210819202022149](./imagens/image-20210819202022149.png)

![image-20210819202031959](./imagens/image-20210819202031959.png)

![image-20210819202040637](./imagens/image-20210819202040637.png)



## **Context**

Um contexto de segurança define configurações de privilégio e controle de acesso para um pod ou contêiner. 

https://kubernetes.io/docs/tasks/configure-pod-container/security-context/



![image-20210819195702800](./imagens/image-20210819195702800.png)

![image-20210819195840584](./imagens/image-20210819195840584.png)



### **Pod Security Police**

Uma *política de segurança de pod* é um recurso em nível de cluster que controla aspectos confidenciais de segurança da especificação de pod. 

https://kubernetes.io/docs/concepts/policy/pod-security-policy/

https://kubernetes.io/docs/concepts/security/pod-security-standards/

![image-20210819200324674](./imagens/image-20210819200324674.png)



![image-20210819200445716](./imagens/image-20210819200445716.png)



![image-20210819200501274](./imagens/image-20210819200501274.png)

![image-20210819200512358](./imagens/image-20210819200512358.png)

![image-20210819200522707](./imagens/image-20210819200522707.png)





## **3  - A´s - Authentication - Authorization - Admission**

![image-20210803213720545](./imagens/image-20210803213720545.png)

![image-20210817211311147](./imagens/image-20210817211311147.png)

![image-20210817214249908](./imagens/image-20210817214249908.png)

### **Authorization(authZ) - RBAC**

- https://kubernetes.io/docs/reference/access-authn-authz/authorization/

- https://kubernetes.io/docs/reference/access-authn-authz/rbac/

- https://blog.lsantos.dev/dando-permissoes-a-usuarios-com-kubernetes/

- https://acloudguru-content-attachment-production.s3-accelerate.amazonaws.com/1596636230976-devops-wb002%20-%20S04-L03%20Managing%20k8s%20Role-Based%20Access%20Control%20%28RBAC%29.pdf

  

Controle de acesso baseado em função (RBAC) em K8s permite que você controle quais usuários são permitidos para fazer e acessar dentro de seu cluster.
Por exemplo, você pode usar RBAC para permitir desenvolvedores para ler metadados e registros de Pods do Kubernetes, mas não faz alterações em
eles.

**Roles** e **ClusterRoles** são Objetos Kubernetes que definem um conjunto de permissões. Esses permissões determinam quais usuários pode fazer no cluster.

![image-20210825213124618](./imagens/image-20210825213124618.png)

- **Role**

  - Define as permissões dentro um determinado namespace

  - As Roles são puramente aditivas (não há regras de "negação")

  - Exemplo  Role

    ```yaml
    apiVersion: rbac.authorization.k8s.io/v1
    kind: Role
    metadata:
      namespace: default
      name: pod-reader
    rules:
    - apiGroups: [""] # "" indicates the core API group
      resources: ["pods"]
      verbs: ["get", "watch", "list"]
    ```

    

- **ClusterRole**

  - Define as permissões em todo o cluster permissões não específicas para um namespace único

  - Exemplo ClusterRole

  - ```yaml
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole
    metadata:
      # "namespace" omitted since ClusterRoles are not namespaced
      name: secret-reader
    rules:
    - apiGroups: [""]
      #
      # at the HTTP level, the name of the resource for accessing Secret
      # objects is "secrets"
      resources: ["secrets"]
      verbs: ["get", "watch", "list"]
    ```

    

**RoleBinding** e **ClusterRoleBinding** são objetos que conectam **Roles** e **ClusterRoles** para usuários.

![image-20210825213435558](./imagens/image-20210825213435558.png)

**RoleBinding**

- Concede permissões dentro de um namespace específico apontando para uma **Role** já criada. 

- Exemplo

  ```yaml
  apiVersion: rbac.authorization.k8s.io/v1
  # This role binding allows "jane" to read pods in the "default" namespace.
  # You need to already have a Role named "pod-reader" in that namespace.
  kind: RoleBinding
  metadata:
    name: read-pods
    namespace: default
  subjects:
  # You can specify more than one "subject"
  - kind: User
    name: jane # "name" is case sensitive
    apiGroup: rbac.authorization.k8s.io
  roleRef:
    # "roleRef" specifies the binding to a Role / ClusterRole
    kind: Role #this must be Role or ClusterRole
    name: pod-reader # this must match the name of the Role or ClusterRole you wish to bind to
    apiGroup: rbac.authorization.k8s.io
  ```

  

**ClusterRoleBinding**

- Concede esse acesso a todo o cluster
- Exemplo

```yaml
apiVersion: rbac.authorization.k8s.io/v1
# This cluster role binding allows anyone in the "manager" group to read secrets in any namespace.
kind: ClusterRoleBinding
metadata:
  name: read-secrets-global
subjects:
- kind: Group
  name: manager # Name is case sensitive
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: secret-reader
  apiGroup: rbac.authorization.k8s.io
```







![image-20210817214420571](./imagens/image-20210817214420571.png)

![image-20210817214515972](./imagens/image-20210817214515972.png)

![image-20210817214551446](C:\Users\brik\AppData\Roaming\Typora\typora-user-images\image-20210817214551446.png)

![image-20210817215453548](./imagens/image-20210817215453548.png)

### **Authentication(authN)**

https://kubernetes.io/pt-br/docs/reference/access-authn-authz/authentication/

- **Proveder ID**
- **Token**

![image-20210817211507347](./imagens/image-20210817211507347.png)

https://kubernetes.io/pt-br/docs/reference/access-authn-authz/authentication/#estrat%C3%A9gias-de-autentica%C3%A7%C3%A3o

![image-20210817211700241](./imagens/image-20210817211700241.png)

https://kubernetes.io/pt-br/docs/reference/access-authn-authz/authentication/#certificados-de-cliente-x509

![image-20210817211912924](./imagens/image-20210817211912924.png)

https://kubernetes.io/pt-br/docs/reference/access-authn-authz/authentication/#arquivo-est%C3%A1tico-de-token

![image-20210817212009664](./imagens/image-20210817212009664.png)

***Não Recomendado*** 



![image-20210817212025851](./imagens/image-20210817212025851.png)

https://kubernetes.io/pt-br/docs/reference/access-authn-authz/authentication/#tokens-de-contas-de-servi%C3%A7o

![image-20210817212038271](./imagens/image-20210817212038271.png)



https://kubernetes.io/docs/reference/access-authn-authz/rbac/



O controle de acesso baseado em função (RBAC) é um método de regular o acesso a recursos de computador ou rede com base nas funções de usuários individuais em sua organização.





### **Admission Control**

https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/

Admission Control é um trecho de código que intercepta solicitações para o servidor da API Kubernetes antes da persistência do objeto, mas depois que a solicitação é autenticada e autorizada. 

![image-20210817220341901](./imagens/image-20210817220341901.png)

![image-20210817220522335](./imagens/image-20210817220522335.png)

![image-20210817220540968](./imagens/image-20210817220540968.png)

https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#is-there-a-recommended-set-of-admission-controllers-to-use

![image-20210817220941657](./imagens/image-20210817220941657.png)



- **Mutatung**

- **Validating**

  

### **Anotações Importantes**

- *Alguns clusters abrem uma porta local insegura, desabilite em Produção;*
- *Deny-by-default;*
- *Kubernetes NÃO faz usuários;*
- *Gerencie os usuários externamente;*

### **Comandos**



| Descrição                             | Comando                                              |
| ------------------------------------- | ---------------------------------------------------- |
| Listar as ClusterRoleBindings         | kubectl.exe get clusterrolebindings                  |
| Listar as ClusterRole                 | kubectl.exe get clusterrole                          |
| Listar as Role de todas as namespaces | kubectl.exe get role --all-namespaces                |
| Listar as Role de namespaces          | kubectl.exe get role -n "*namespaces*"               |
| Lista uma role especifica             | kubectl.exe get clusterrole "*nome-da-role*"         |
| Lista uma role especifica em YAML     | kubectl.exe get clusterrole "*nome-da-role*" -o yaml |
| Descrição da ClusterRole              | kubectl.exe describe clusterrole "*nome-da-role*"    |
|                                       |                                                      |
|                                       |                                                      |









## **Tipos de Ataques**

### **Attack Vectors**

![image-20210816200810208](./imagens/image-20210816200810208.png)

### **Access to etcd**

![image-20210816200900986](./imagens/image-20210816200900986.png)

### **Access Kubernetes API Server**

![image-20210816200927328](./imagens/image-20210816200927328.png)

### **Intercept/Modify/Inject Control Plane**

![image-20210816200949941](./imagens/image-20210816200949941.png)

### **Access via Kubelet API**

![image-20210816201147842](./imagens/image-20210816201147842.png)

### **Compromise Container Runtime**

![image-20210816201553858](./imagens/image-20210816201553858.png)

### **Intercept/Modify/Inject Application Traffic**

![image-20210816201628340](./imagens/image-20210816201628340.png)

### **Escape Container Host**

![image-20210816201715269](./imagens/image-20210816201715269.png)

### **Vulnarebilities**

![image-20210816202113781](./imagens/image-20210816202113781.png)



## **Principle of Least Privilege**

![image-20210816202456943](./imagens/image-20210816202456943.png)

O princípio significa dar a uma [conta de usuário](https://en.wikipedia.org/wiki/User_account) ou processo apenas os privilégios que são essenciais para executar sua função pretendida. Por exemplo, uma conta de usuário com o único propósito de criar backups não precisa instalar software: portanto, ela tem direitos apenas para executar backup e aplicativos relacionados a backup.

https://en.wikipedia.org/wiki/Principle_of_least_privilege#cite_note-1

- Utilizar namespaces;
- Serviceaccounts;
- Roles

## **Boundaries**

![image-20210816203347906](./imagens/image-20210816203347906.png)

### **Cluster**

![image-20210816204531592](./imagens/image-20210816204531592.png)

### **Node**

![image-20210816204546321](./imagens/image-20210816204546321.png)

### **Namespaces**

![image-20210816204602020](./imagens/image-20210816204602020.png)

### **Pod**

![image-20210816204612221](./imagens/image-20210816204612221.png)

### **Container**

![image-20210816204625231](./imagens/image-20210816204625231.png)



## **TLS**

![image-20210816205135814](./imagens/image-20210816205135814.png)

![image-20210816205600729](./imagens/image-20210816205600729.png)

### **API Server**

![image-20210816205746574](C:\Users\brik\AppData\Roaming\Typora\typora-user-images\image-20210816205746574.png)

### **ETCD**

![image-20210816205800579](C:\Users\brik\AppData\Roaming\Typora\typora-user-images\image-20210816205800579.png)

### **Scheduler**

![image-20210816205811280](C:\Users\brik\AppData\Roaming\Typora\typora-user-images\image-20210816205811280.png)

### **Controller**

![image-20210816205824874](C:\Users\brik\AppData\Roaming\Typora\typora-user-images\image-20210816205824874.png)

### **Services**

![image-20210816205839626](C:\Users\brik\AppData\Roaming\Typora\typora-user-images\image-20210816205839626.png)



## **Firewall and Virtual Private Networking**

![image-20210816210251097](C:\Users\brik\AppData\Roaming\Typora\typora-user-images\image-20210816210251097.png)

https://v1-17.docs.kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/

### **Load Balancers**

![image-20210816210312854](./imagens/image-20210816210312854.png)



## **Using kube-bench toHarden a Cluster**

![image-20210816210503115](./imagens/image-20210816210503115.png)

https://github.com/aquasecurity/kube-bench

**Setup**

```shell
$ kubectl apply -f job.yaml
job.batch/kube-bench created

$ kubectl get pods
NAME                      READY   STATUS              RESTARTS   AGE
kube-bench-j76s9   0/1     ContainerCreating   0          3s

# Wait for a few seconds for the job to complete
$ kubectl get pods
NAME                      READY   STATUS      RESTARTS   AGE
kube-bench-j76s9   0/1     Completed   0          11s

# The results are held in the pod's logs
kubectl logs kube-bench-j76s9
[INFO] 1 Master Node Security Configuration
[INFO] 1.1 API Server
```



## **Securing the Kubelet**

https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/

![image-20210816211300140](./imagens/image-20210816211300140.png)

https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/kubelet-integration/

https://kubernetes.io/docs/tasks/administer-cluster/reconfigure-kubelet/

## **Securing ETCD**

![image-20210816213207099](./imagens/image-20210816213207099.png)



## **Melhores Práticas**

https://kubernetes.io/docs/tasks/administer-cluster/securing-a-cluster/



##############################################################################################

# **Monitoring**

**TODO - Mudar o setup do monitoramento para Helm.**

https://docs.aws.amazon.com/pt_br/eks/latest/userguide/prometheus.html

https://www.eksworkshop.com/intermediate/240_monitoring/deploy-prometheus/

https://github.com/aws/eks-charts

![image-20210804203946101](./imagens/image-20210804203946101.png)





## **Prometheus**

https://prometheus.io/

![image-20210804204245381](./imagens/image-20210804204245381.png)

![image-20210809212642725](./imagens/image-20210809212642725.png)

### **Client Libraries**

https://prometheus.io/docs/instrumenting/clientlibs/

Antes de monitorar seus serviços, você precisa adicionar instrumentação ao código por meio de uma das bibliotecas cliente do Prometheus.

Quando o Prometheus raspa o endpoint HTTP da sua instância, a biblioteca cliente envia o estado atual de todas as métricas rastreadas para o servidor.

![image-20210804204703337](./imagens/image-20210804204703337.png)



### **Exports**

https://prometheus.io/docs/instrumenting/exporters/

Existem várias bibliotecas e servidores que ajudam a exportar métricas existentes de sistemas de terceiros como métricas do Prometheus.



![image-20210804204738616](./imagens/image-20210804204738616.png)



### **Service Discovery**

https://prometheus.io/blog/2015/06/01/advanced-service-discovery/

![image-20210804205014829](./imagens/image-20210804205014829.png)



### **Scraping**

![image-20210804205014829](./imagens/image-20210804205014829.png)





### **Setup Prometheus**

https://github.com/linuxacademy/content-kubernetes-prometheus-env



**Setup namespace**

```bash
kubectl apply -f namespaces.yml
```

Verificar se o recurso foi criado da corretamente.

```bash
kubectl get ns
```

![image-20210809205202305](./imagens/image-20210809205202305.png)

**Setup Config MAP**

Tem que alterar no job node-exporter os ips dos targets para os ips do master e dos nodes.

```bash
kubectl apply -f prometheus-config-map.yml
```

Verificar se o recurso foi criado da corretamente.

```bash
kubectl.exe get configmaps -n monitoring
```

![image-20210809205232171](./imagens/image-20210809205232171.png)

**Setup Deployment**

Cria 2 containeres - Prometheus e Watch

```bash
kubectl apply -f prometheus-deployment.yml
```

Verificar se o recurso foi criado da corretamente.

```bash
kubectl.exe get deploy -n monitoring
```

![image-20210809205134186](./imagens/image-20210809205134186.png)

**Setup Prometheus Service** 

```bash
kubectl.exe apply -f prometheus-service.yml 
```

Verificar se o recurso foi criado da corretamente.

```bash
kubectl.exe get svc -n monitoring
```



![image-20210809210122572](./imagens/image-20210809210122572.png)



**Setup ClusterRole**

```bash
kubectl.exe apply -f clusterRole.yml 
```



**Setup kube-state-metric**

https://github.com/kubernetes/kube-state-metrics

```bash
kubectl.exe apply -f kube-state-metrics.yml
```



## **Grafana**

![image-20210809214137423](C:\Users\brik\AppData\Roaming\Typora\typora-user-images\image-20210809214137423.png)



### **Setup Grafana**

**Deployment**

```bash
kubectl.exe apply -f grafana-deployment.yml
```

Verificar se o recurso foi criado da corretamente.

```bash
kubectl.exe get deploy -n monitoring
```



![image-20210809214517887](./imagens/image-20210809214517887.png)

**Service**

```bash
kubectl.exe apply -f grafana-service.yml
```

Verificar se o recurso foi criado da corretamente.

```bash
kubectl.exe get svc -n monitoring
```

![image-20210809214745579](./imagens/image-20210809214745579.png)



## **Node Exporter**

https://prometheus.io/docs/guides/node-exporter/



![image-20210809215541313](./imagens/image-20210809215541313.png)





**Avaliar** 

Fazer o do Linux tips

https://www.metricfire.com/blog/how-to-deploy-prometheus-on-kubernetes/#Deployment

https://devopscube.com/setup-prometheus-monitoring-on-kubernetes/

##############################################################################################

# **Setup do Kubernetes**

**Links**

https://acloudguru-content-attachment-production.s3-accelerate.amazonaws.com/1623334133949-Building%20a%20Kubernetes%20Cluster.pdf

https://docs.docker.com/engine/install/ubuntu/

https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/

https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/

https://buildvirtual.net/deploy-a-kubernetes-cluster-using-ansible/

https://www.linuxsysadmins.com/install-kubernetes-cluster-with-ansible/

https://kubernetes.io/blog/2019/03/15/kubernetes-setup-using-ansible-and-vagrant/

**Configura módulos**

// - Resolve problema de versão

https://stackoverflow.com/questions/49721708/how-to-install-specific-version-of-kubernetes

Crie o arquivo `/etc/modules-load.d/k8s.conf` com o seguinte conteúdo em todos os seus nós.

```bash
sudo echo "br_netfilter" > /etc/modules-load.d/k8s.conf
sudo echo "ip_vs" >> /etc/modules-load.d/k8s.conf
sudo echo "ip_vs_rr" >> /etc/modules-load.d/k8s.conf
sudo echo "ip_vs_sh" >> /etc/modules-load.d/k8s.conf
sudo echo "ip_vs_wrr" >> /etc/modules-load.d/k8s.conf
sudo echo "nf_conntrack_ipv4" >> /etc/modules-load.d/k8s.conf
```

Atualiza distro

```bash
apt-get update && apt-get upgrade -y
```

**Instala Docker**

```bash
sudo curl -fsSL https://get.docker.com | bash
```

**Configura Cgroup**

```bash

# cat > /etc/docker/daemon.json <<EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2"
}
EOF

sudo mkdir -p /etc/systemd/system/docker.service.d

sudo systemctl daemon-reload

sudo systemctl restart docker

docker info | grep -i cgroup
```

Se a saída foi `Cgroup Driver: systemd`, tudo certo!

**Configura Repo K8S**

```bash
sudo apt-get update && apt-get install -y apt-transport-https gnupg2

sudo curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -

sudo echo "deb http://apt.kubernetes.io/ kubernetes-xenial main" > /etc/apt/sources.list.d/kubernetes.list

sudo apt-get update
```

**Instala pacotes K8S**

```bash
sudo apt-get install -y kubelet kubeadm kubectl
```

**Baixa imagens K8S**

```bash
sudo kubeadm config images pull
```

 **Desabilita Swap**

```bash
swapoff -a
```

**Inicia o Master Node**

```shell
kubeadm init --apiserver-advertise-address $(hostname -i)
```

**Seta saída do kubeadm**

```shell
sudo cp /etc/kubernetes/admin.conf $HOME/
sudo chown $(id -u):$(id -g) $HOME/admin.conf
export KUBECONFIG=$HOME/admin.conf
```

3 - Configura plugin rede

```shell
kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version \|base64 \|tr -d '\n')"
```

4 - Join dos nodes

```bash
kubeadm join --discovery-token-unsafe-skip-ca-verification --token=102952.1a7dd4cc8d1f4cc5 172.17.0.69:6443
```

##############################################################################################

# **Best  Practices**

- **ETCD** - em produção sempre manter fora do Master e em HA



##############################################################################################

# **Vídeos**

## **RBAC**

- **Webinar: Role based access control (RBAC) policies in Kubernetes** - https://www.youtube.com/watch?v=CnHTCTP8d48
- **Effective RBAC - Jordan Liggitt, Red Hat** - https://www.youtube.com/watch?v=Nw1ymxcLIDI
- **[ Kube 68 ] Kubernetes RBAC Demo | Creating Users and Roles** - https://www.youtube.com/watch?v=U67OwM-e9rQ

##############################################################################################

# **Exemplos**

**service-clusterip.yaml**

```yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    run: nginx
  name: nginx-clusterip
  namespace: default
spec:
  externalTrafficPolicy: Cluster
  ports:
  - port: 80
    protocol: TCP
    targetPort: 80
  selector:
    run: nginx
  sessionAffinity: None
  type: ClusterIP
```

**service-nodeip.yaml**

```yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    run: nginx
  name: nginx-nodeport
  namespace: default
spec:
  externalTrafficPolicy: Cluster
  ports:
  - nodePort: 32548
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    run: nginx
  sessionAffinity: ClientIP
  type: NodePort
```



**service-loadbalancer.yaml**

```yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    run: nginx
  name: nginx-loadbalancer
  namespace: default
spec:
  externalTrafficPolicy: Cluster
  ports:
  - nodePort: 32548
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    run: nginx
  sessionAffinity: None
  type: LoadBalancer
```



**deployment-limitado.yaml** 

```yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  labels:
    run: nginx
  name: nginx-limitado
  namespace: default
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 2
  selector:
    matchLabels:
      run: nginx
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        run: nginx
    spec:
      containers:
      - image: nginx
        imagePullPolicy: Always
        name: nginx
        ports:
        - containerPort: 80
          protocol: TCP
        resources:
          limits:  ## Quando o K8S vai liberar para esse deployment
            memory: 128Mi
            cpu: 1
          requests: ## Minimo garantido que o K8S vai liberar para esse deployment
            memory: 96Mi
            cpu: 1
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
```

```yaml
Atenção! 1 core de CPU corresponde a 1000m (1000 milicore). Ao especificar 200m, estamos querendo reservar 20% de 1 core da CPU. Se fosse informado o valor 0.2 teria o mesmo efeito, ou seja, seria reservado 20% de 1 core da CPU.
```

##############################################################################################

# **Comandos **







|                           Comando                            | Descrição              |
| :----------------------------------------------------------: | :--------------------- |
|                                                              |                        |
|                                                              |                        |
|  echo "source <(kubectl completion bash)" >> /root/.bashrc   | auto complete          |
|                                                              |                        |
| aws eks --region "*region*" update-kubeconfig --name "*cluster-name*" | Conecta no cluster EKS |
|                                                              |                        |
|                                                              |                        |
|                                                              |                        |
|                                                              |                        |
|                                                              |                        |
|                                                              |                        |
|                                                              |                        |
|                                                              |                        |
|                                                              |                        |
|                                                              |                        |
|                                                              |                        |
|                                                              |                        |
|                                                              |                        |
|                                                              |                        |
|                                                              |                        |
|                                                              |                        |
|                                                              |                        |
|                                                              |                        |
|                                                              |                        |
|                                                              |                        |
|                                                              |                        |
|                                                              |                        |
|                                                              |                        |
|                                                              |                        |

##############################################################################################

# **Links Úteis**

**Tipos de topologias de K8s multi-master**

https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/



**Instalação kubeadm, kubelet e kubectl**

https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/



**Instalação Kubernetes multi-master**

https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/



**HAproxy**

https://www.haproxy.org/



**Options for Highly Available topology**

https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/ha-topology/



**Creating Highly Available clusters with kubeadm**

https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/
